import Foundation
import NuguClientKit
import NuguLoginKit
import NuguCore
import NuguAgents
import AVFoundation
import NuguServiceKit

@objc(NuguBridge)
class NuguBridge: NSObject {
    
    // MARK: - Properties
    private var nuguClient: NuguClient?
    private let audioSessionManager = AudioSessionManager()
    private var currentRecordingPath: String?
    
    // NUGU ê´€ë ¨ ì†ì„±
    private var keywordDetector: KeywordDetector?
    private var keywordDetectorState: KeywordDetectorState = .inactive
    
    // ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸¡ì •ì„ ìœ„í•œ ì†ì„±ë“¤
    private let audioEngine = AVAudioEngine()
    private var audioLevel: Float = 0
    private var silenceTimer: Timer?
    private var silenceStartTime: Date?
    private let silenceThreshold: Float = 0.03
    private let maxSilenceDuration: TimeInterval = 3.0
    private var isRecording: Bool = false
    
    // MARK: - React Native Bridge Setup
    @objc static func requiresMainQueueSetup() -> Bool {
        return true
    }
    
    // MARK: - Public Methods
    @objc func initialize(_ resolve: @escaping RCTPromiseResolveBlock,
                     rejecter reject: @escaping RCTPromiseRejectBlock) {
    DispatchQueue.main.async { [weak self] in
        guard let self = self else {
            reject("NO_INSTANCE", "NuguBridge instance is nil", nil)
            return
        }
        
        AVAudioSession.sharedInstance().requestRecordPermission { granted in
            if granted {
                do {
                    print("ğŸ¤ NUGU SDK ì´ˆê¸°í™” ì‹œì‘")
                    
                    // NuguClient ì„¤ì •
                    let clientBuilder = NuguClient.Builder()
                    
                    // KeywordDetector ì„¤ì •
                    self.keywordDetector = clientBuilder.keywordDetector
                    self.keywordDetector?.delegate = self
                    
                    // NUGU í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                    self.nuguClient = clientBuilder.build()
                    
                    // ì˜¤ë””ì˜¤ ì„¸ì…˜ ì„¤ì •
                    try self.audioSessionManager.setCategory(.playAndRecord, mode: .default)
                    
                    print("âœ… NUGU SDK ì´ˆê¸°í™” ì„±ê³µ")
                    resolve(nil)
                    
                    // í‚¤ì›Œë“œ ê°ì§€ ì‹œì‘
                    self.startKeywordDetection()
                    
                } catch {
                    print("âŒ NUGU SDK ì´ˆê¸°í™” ì‹¤íŒ¨: \(error)")
                    reject("INIT_ERROR", "Failed to initialize NUGU SDK: \(error.localizedDescription)", error)
                }
            } else {
                print("âŒ ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë¨")
                reject("PERMISSION_ERROR", "Microphone permission denied", nil)
            }
        }
    }
}

    @objc func startRecording(_ resolve: @escaping RCTPromiseResolveBlock,
                         rejecter reject: @escaping RCTPromiseRejectBlock) {
    DispatchQueue.main.async { [weak self] in
        guard let self = self else {
            reject("NO_INSTANCE", "NuguBridge instance is nil", nil)
            return
        }
        
        guard let client = self.nuguClient else {
            reject("NO_CLIENT", "NUGU Client is not initialized", nil)
            return
        }
        
        guard !self.isRecording else {
            reject("ALREADY_RECORDING", "Recording is already in progress", nil)
            return
        }
        
        // í‚¤ì›Œë“œ ê°ì§€ ì¤‘ì§€
        stopKeywordDetection()
        
        do {
            try self.audioSessionManager.setActive(true)
            print("ğŸ¤ ë…¹ìŒ ì‹œì‘")
            
            // ì˜¤ë””ì˜¤ ì—”ì§„ ì„¤ì •
            try self.setupAudioEngine()
            
            // íŒŒì¼ ê²½ë¡œ ì„¤ì •
            let fileManager = FileManager.default
            let documentsDirectory = fileManager.urls(for: .documentDirectory, in: .userDomainMask)[0]
            
            // í˜„ì¬ ë‚ ì§œ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
            let dateFormatter = DateFormatter()
            dateFormatter.dateFormat = "yyyyMMdd_HHmmss"
            let timestamp = dateFormatter.string(from: Date())
            let fileName = "recording.m4a"
            let fullFileName = "\(timestamp)_\(fileName)"
            
            let fileURL = documentsDirectory.appendingPathComponent(fullFileName)
            self.currentRecordingPath = fileURL.path
            
            // ë””ë ‰í† ë¦¬ í™•ì¸ ë° ìƒì„±
            do {
                try fileManager.createDirectory(at: documentsDirectory, withIntermediateDirectories: true, attributes: nil)
                
                // ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•œë‹¤ë©´ ì‚­ì œ
                if fileManager.fileExists(atPath: fileURL.path) {
                    try fileManager.removeItem(at: fileURL)
                }
                print("ğŸ“ ë…¹ìŒ íŒŒì¼ ê²½ë¡œ ì¤€ë¹„ ì™„ë£Œ: \(fileURL.path)")
            } catch {
                print("âŒ ë…¹ìŒ íŒŒì¼ ê²½ë¡œ ì„¤ì • ì‹¤íŒ¨: \(error)")
                reject("FILE_SETUP_ERROR", "Failed to setup recording file path: \(error.localizedDescription)", error)
                return
            }
            
            var stateObserved = false
            let timeout = DispatchTime.now() + 5.0
            
            client.asrAgent.startRecognition(
                initiator: .tap,
                completion: { [weak self] state in
                    guard let self = self else { return }
                    
                    switch state {
                    case .prepared:
                        if !stateObserved {
                            stateObserved = true
                            self.isRecording = true
                            self.startSilenceDetection()
                            print("âœ… ìŒì„±ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ")
                            resolve(nil)
                        }
                    case .sent:
                        print("ğŸ¤ ìŒì„± ì¸ì‹ ë°ì´í„° ì „ì†¡ë¨")
                    case .received(let directive):
                        print("âœ… ì‘ë‹µ ìˆ˜ì‹ ë¨: \(directive)")
                    case .finished:
                        print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ")
                    case .error(let error):
                        if !stateObserved {
                            stateObserved = true
                            self.isRecording = false
                            print("âŒ ìŒì„±ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨: \(error)")
                            reject("RECORDING_ERROR", "Failed to start recording: \(error.localizedDescription)", error)
                        }
                    }
                }
            )
            
            DispatchQueue.main.asyncAfter(deadline: timeout) {
                if !stateObserved {
                    self.isRecording = false
                    print("âš ï¸ ìŒì„±ì¸ì‹ ìƒíƒœ í™•ì¸ íƒ€ì„ì•„ì›ƒ")
                    reject("TIMEOUT", "Recognition state observation timed out", nil)
                }
            }
            
        } catch {
            print("âŒ ì˜¤ë””ì˜¤ ì„¸ì…˜ í™œì„±í™” ì‹¤íŒ¨: \(error)")
            reject("RECORDING_ERROR", "Failed to activate audio session: \(error.localizedDescription)", error)
        }
    }
}
    
    @objc func stopRecording(_ resolve: @escaping RCTPromiseResolveBlock,
                            rejecter reject: @escaping RCTPromiseRejectBlock) {
        DispatchQueue.main.async { [weak self] in
            guard let self = self else {
                reject("NO_INSTANCE", "NuguBridge instance is nil", nil)
                return
            }
            
            guard let client = self.nuguClient else {
                reject("NO_CLIENT", "NUGU Client is not initialized", nil)
                return
            }
            
            guard self.isRecording else {
                reject("NOT_RECORDING", "No active recording session", nil)
                return
            }
            
            // ì˜¤ë””ì˜¤ ì—”ì§„ ì •ë¦¬
            self.audioEngine.inputNode.removeTap(onBus: 0)
            self.audioEngine.stop()
            
            // íƒ€ì´ë¨¸ ì •ë¦¬
            self.silenceTimer?.invalidate()
            self.silenceTimer = nil
            
            // ë…¹ìŒ ì¤‘ì§€
            client.asrAgent.stopRecognition()
            self.isRecording = false
            
            // íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            let fileManager = FileManager.default
            let response: [String: Any] = [
                "audioPath": self.currentRecordingPath ?? "",
                "sttResult": "",
                "exists": fileManager.fileExists(atPath: self.currentRecordingPath ?? "")
            ]
            
            do {
                try self.audioSessionManager.setActive(false)
                print("âœ… ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ")
                print("ğŸ“ ë…¹ìŒ íŒŒì¼ ê²½ë¡œ: \(self.currentRecordingPath ?? "ì—†ìŒ")")
                
                // í‚¤ì›Œë“œ ê°ì§€ ë‹¤ì‹œ ì‹œì‘
                self.startKeywordDetection()
                
                resolve(response)
            } catch {
                print("âš ï¸ ì˜¤ë””ì˜¤ ì„¸ì…˜ ë¹„í™œì„±í™” ì‹¤íŒ¨: \(error)")
                resolve(response)
            }
        }
    }
    
    private func setupAudioEngine() throws {
    let inputNode = audioEngine.inputNode
    let recordingFormat = inputNode.outputFormat(forBus: 0)
    
    // AudioFile ìƒì„±
    let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    let dateFormatter = DateFormatter()
    dateFormatter.dateFormat = "yyyyMMdd_HHmmss"
    let timestamp = dateFormatter.string(from: Date())
    let fileName = "\(timestamp)_recording.m4a"
    let audioURL = documentsPath.appendingPathComponent(fileName)
    
    // ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•œë‹¤ë©´ ì‚­ì œ
    try? FileManager.default.removeItem(at: audioURL)
    
    let audioFile = try AVAudioFile(forWriting: audioURL, settings: recordingFormat.settings)
    self.currentRecordingPath = audioURL.path
    
    // ì˜¤ë””ì˜¤ íƒ­ ì„¤ì •
    inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
        guard let self = self else { return }
        
        // ë²„í¼ë¥¼ íŒŒì¼ì— ê¸°ë¡
        try? audioFile.write(from: buffer)
        
        // ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚°
        let channelData = buffer.floatChannelData?[0]
        let frameLength = UInt32(buffer.frameLength)
        
        var sum: Float = 0
        for i in 0..<Int(frameLength) {
            sum += fabsf(channelData?[i] ?? 0)
        }
        
        self.audioLevel = sum / Float(frameLength)
    }
    
    try audioEngine.start()
}
    
    // MARK: - Private Methods - Silence Detection
    private func startSilenceDetection() {
        silenceStartTime = nil
        silenceTimer?.invalidate()
        
        silenceTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            guard let self = self, self.isRecording else { return }
            self.handleAudioLevel(self.audioLevel)
        }
    }
    
    private func handleAudioLevel(_ level: Float) {
        if level < silenceThreshold {
            if silenceStartTime == nil {
                silenceStartTime = Date()
            } else if let startTime = silenceStartTime {
                let silenceDuration = Date().timeIntervalSince(startTime)
                if silenceDuration >= maxSilenceDuration {
                    stopRecordingDueToSilence()
                }
            }
        } else {
            silenceStartTime = nil
        }
    }
    
    private func stopRecordingDueToSilence() {
        guard isRecording else { return }
        
        print("ğŸ”‡ 3ì´ˆ ë™ì•ˆ ë¬µìŒ ê°ì§€ë¨ - ë…¹ìŒ ì¤‘ì§€")
        stopRecording({ _ in
            print("âœ… ë…¹ìŒ ìë™ ì¤‘ì§€ ì™„ë£Œ")
        }, rejecter: { code, message, error in
            print("âŒ ë…¹ìŒ ìë™ ì¤‘ì§€ ì‹¤íŒ¨: \(message)")
        })
    }
    
    // MARK: - Private Methods - Keyword Detection
    private func startKeywordDetection() {
        keywordDetector?.start()
        print("âœ… í‚¤ì›Œë“œ ê°ì§€ ì‹œì‘")
    }
    
    private func stopKeywordDetection() {
        keywordDetector?.stop()
        print("â¹ í‚¤ì›Œë“œ ê°ì§€ ì¤‘ì§€")
    }
    
    deinit {
        audioEngine.stop()
        silenceTimer?.invalidate()
        keywordDetector?.stop()
    }
}

// MARK: - KeywordDetectorDelegate
extension NuguBridge: KeywordDetectorDelegate {
    func keywordDetectorDidDetect(keyword: String?, data: Data, start: Int, end: Int, detection: Int) {
        print("ğŸ¯ í‚¤ì›Œë“œ ê°ì§€ë¨: \(keyword ?? "unknown")")
        
        // í‚¤ì›Œë“œ ê°ì§€ í›„ ASR ì‹œì‘
        nuguClient?.asrAgent.startRecognition(
            initiator: .wakeUpWord(keyword: keyword, data: data, start: start, end: end, detection: detection),
            completion: { [weak self] state in
                switch state {
                case .prepared:
                    print("ğŸ‘‚ ìŒì„± ì¸ì‹ ì¤€ë¹„ ì¤‘...")
                case .sent:
                    print("ğŸ¤ ìŒì„± ì¸ì‹ ë°ì´í„° ì „ì†¡ë¨")
                case .received(let directive):
                    print("âœ… ì‘ë‹µ ìˆ˜ì‹ ë¨: \(directive)")
                case .finished:
                    print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ")
                case .error(let error):
                    print("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨: \(error)")
                }
            }
        )
    }
    
    func keywordDetectorDidError(_ error: Error) {
        print("âŒ í‚¤ì›Œë“œ ê°ì§€ ì˜¤ë¥˜: \(error.localizedDescription)")
    }
    
    func keywordDetectorStateDidChange(_ state: KeywordDetectorState) {
        keywordDetectorState = state
        print("ğŸ”„ í‚¤ì›Œë“œ ê°ì§€ ìƒíƒœ ë³€ê²½: \(state)")
    }
}

// MARK: - Audio Session Manager
private class AudioSessionManager {
    func setCategory(_ category: AVAudioSession.Category, mode: AVAudioSession.Mode) throws {
        try AVAudioSession.sharedInstance().setCategory(category, mode: mode, options: [.defaultToSpeaker, .allowBluetooth])
    }
    
    func setActive(_ active: Bool) throws {
        try AVAudioSession.sharedInstance().setActive(active)
    }
}
